heat_template_version: 2013-05-23

parameters:
  master:
    label: master
    type: string
  nodename:
    label: nodename
    type: string
  nodeip:
    label: nodeip
    type: string
  vpn_username:
    label: vpn_username
    type: string
  vpn_password:
    label: vpn_password
    type: string
  subnet:
    label: subnet
    type: string
  network:
    label: network
    type: string
  security_group:
    label: security_group
    type: string
  keypair_name:
    description: Keypair to inject in instance
    label: SSH Keypair
    type: string
  domain:
    description: Wildcarded domain, ex example.com must have a *.example.com DNS entry
    label: Cloud DNS
    type: string
  flavor_name:
    label: Instance Type (Flavor)
    description: Flavor to use for the deployed instance
    type: string
  volume_size:
    label: volume_size
    type: string
  volume_type:
    label: volume_type
    type: string

resources:
  volume:
    type: OS::Cinder::Volume
    properties:
      size: { get_param: volume_size }
      volume_type: { get_param: volume_type }
      metadata:
        fs_type: ext4

  volume_attachement:
    type: OS::Cinder::VolumeAttachment
    properties:
      instance_uuid: { get_resource: node }
      mountpoint: /dev/vdb
      volume_id: { get_resource: volume }

  port:
    type: OS::Neutron::Port
    properties:
      network: { get_param: network }
      fixed_ips:
        - ip_address: { get_param: nodeip }
          subnet_id: { get_param: subnet }
      security_groups:
        - { get_param: security_group }

  node:
    type: OS::Nova::Server
    properties:
      key_name: { get_param: keypair_name }
      image: CoreOS Stable 899.13
      flavor: { get_param: flavor_name }
      user_data_format: RAW
      name: { get_param: nodename}
      networks:
        - port: { get_resource: port }
      user_data:
        str_replace:
          params:
            $private_ipv4: { get_attr: [ port, fixed_ips, 0, ip_address ] }
            $domain: { get_param: domain }
            $master: { get_param: master }
            $fqdn: { get_param: nodename }
            $vpn_username: { get_param: vpn_username }
            $vpn_password: { get_param: vpn_password }
          template: |
            #cloud-config
            write_files:
              - path: /etc/flannel/options.env
                permissions: 0644
                owner: "root:root"
                content: |
                  FLANNELD_IFACE=$private_ipv4
                  FLANNELD_ETCD_ENDPOINTS=http://localhost:2379
              - path: /opt/format-data.sh
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  if [ "$(blkid /dev/vdb | grep ext4 | wc -l)" == "1" ]; then
                    echo 'Volume ready'
                  else
                    /usr/sbin/wipefs -f /dev/vdb
                    /usr/sbin/mkfs.ext4 -F /dev/vdb
                  fi
              - path: /etc/kubernetes/worker-$fqdn-kubeconfig.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Config
                  clusters:
                  - name: local
                    cluster:
                      certificate-authority: /etc/kubernetes/ssl/ca.pem
                  users:
                  - name: kubelet
                    user:
                      client-certificate: /etc/kubernetes/ssl/worker-$fqdn.pem
                      client-key: /etc/kubernetes/ssl/worker-$fqdn-key.pem
                  contexts:
                  - context:
                      cluster: local
                      user: kubelet
                    name: kubelet-context
                  current-context: kubelet-context
              - path: /etc/kubernetes/manifests/kube-proxy.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Pod
                  metadata:
                    name: kube-proxy
                    namespace: kube-system
                  spec:
                    hostNetwork: true
                    containers:
                    - name: kube-proxy
                      image: quay.io/coreos/hyperkube:v1.2.0_coreos.0
                      command:
                      - /hyperkube
                      - proxy
                      - --master=https://$master
                      - --kubeconfig=/etc/kubernetes/worker-$fqdn-kubeconfig.yaml
                      - --proxy-mode=iptables
                      securityContext:
                        privileged: true
                      volumeMounts:
                        - mountPath: /etc/ssl/certs
                          name: "ssl-certs"
                        - mountPath: /etc/kubernetes/worker-$fqdn-kubeconfig.yaml
                          name: "kubeconfig"
                          readOnly: true
                        - mountPath: /etc/kubernetes/ssl
                          name: "etc-kube-ssl"
                          readOnly: true
                    volumes:
                      - name: "ssl-certs"
                        hostPath:
                          path: "/usr/share/ca-certificates"
                      - name: "kubeconfig"
                        hostPath:
                          path: "/etc/kubernetes/worker-$fqdn-kubeconfig.yaml"
                      - name: "etc-kube-ssl"
                        hostPath:
                          path: "/etc/kubernetes/ssl"
              - path: /opt/bin/kubelet-wrapper
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  # Wrapper for launching kubelet via rkt-fly stage1.
                  #
                  # Make sure to set KUBELET_VERSION to an image tag published here:
                  # https://quay.io/repository/coreos/hyperkube?tab=tags Alternatively,
                  # override $KUBELET_ACI to a custom location.

                  set -e

                  if [ -z "${KUBELET_VERSION}" ]; then
                      echo "ERROR: must set KUBELET_VERSION"
                      exit 1
                  fi

                  KUBELET_ACI="${KUBELET_ACI:-quay.io/coreos/hyperkube}"

                  mkdir --parents /etc/kubernetes
                  mkdir --parents /var/lib/docker
                  mkdir --parents /var/lib/kubelet
                  mkdir --parents /run/kubelet

                  exec /usr/bin/rkt run \
                    --volume etc-kubernetes,kind=host,source=/etc/kubernetes \
                    --volume etc-kubernetes-ssl,kind=host,source=/etc/kubernetes/ssl \
                    --volume etc-ssl-certs,kind=host,source=/usr/share/ca-certificates \
                    --volume var-lib-docker,kind=host,source=/var/lib/docker \
                    --volume var-lib-kubelet,kind=host,source=/var/lib/kubelet \
                    --volume run,kind=host,source=/run \
                    --mount volume=etc-kubernetes,target=/etc/kubernetes \
                    --mount volume=etc-kubernetes-ssl,target=/etc/kubernetes/ssl \
                    --mount volume=etc-ssl-certs,target=/etc/ssl/certs \
                    --mount volume=var-lib-docker,target=/var/lib/docker \
                    --mount volume=var-lib-kubelet,target=/var/lib/kubelet \
                    --mount volume=run,target=/run \
                    --trust-keys-from-https \
                    $RKT_OPTS \
                    --stage1-path=/usr/share/rkt/stage1-fly.aci \
                    ${KUBELET_ACI}:${KUBELET_VERSION} --exec=/kubelet -- "$@"
              - path: /etc/environment
                permissions: 0666
                owner: "root:root"
                content: |
                  COREOS_PRIVATE_IPV4=$private_ipv4
                  COREOS_PUBLIC_IPV4=$private_ipv4
                  ETCD_ADDR=localhost:2379
                  ETCD_PEER_ADDR=$master:2380
                  TOOLBOX_DOMAIN=$domain
              - path: /opt/kubernetes-init-ssl.sh
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  mkdir -p /etc/kubernetes/ssl
                  cd /etc/kubernetes/ssl
                  # Worker Config
                  cat <<EOF > worker-openssl.cnf
                  [req]
                  req_extensions = v3_req
                  distinguished_name = req_distinguished_name
                  [req_distinguished_name]
                  [ v3_req ]
                  basicConstraints = CA:FALSE
                  keyUsage = nonRepudiation, digitalSignature, keyEncipherment
                  subjectAltName = @alt_names
                  [alt_names]
                  IP.1 = \$ENV::WORKER_IP
                  EOF
                  # Worker CA
                  echo "Waiting for Kubernetes to be Started..."
                  K8S="http://$master:8080"
                  while true
                  do
                      echo "Trying: $K8S"
                      if [ -n "$(curl --silent "$K8S/version")" ]; then
                          ACTIVE_K8S=$K8S
                          break
                      fi
                      sleep 1
                      if [ -n "$ACTIVE_K8S" ]; then
                          break
                      fi
                  done
                  etcdctl get /ssl/ca > ca.pem
                  etcdctl get /ssl/key > ca-key.pem
                  openssl genrsa -out worker-$fqdn-key.pem 2048
                  WORKER_IP=$private_ipv4 openssl req -new -key worker-$fqdn-key.pem -out worker-$fqdn.csr -subj "/CN=$fqdn" -config worker-openssl.cnf
                  WORKER_IP=$private_ipv4 openssl x509 -req -in worker-$fqdn.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out worker-$fqdn.pem -days 365 -extensions v3_req -extfile worker-openssl.cnf
                  # Set permissions
                  chmod 600 /etc/kubernetes/ssl/*-key.pem
                  chown root:root /etc/kubernetes/ssl/*-key.pem
            coreos:
              etcd2:
                proxy: on
                listen-client-urls: http://localhost:2379
                initial-cluster: etcdserver=http://$master:2380
              units:
                - name: etcd2.service
                  command: start
                - name: generatessl.service
                  command: start
                  content: |
                    [Unit]
                    Requires=etcd2.service
                    After=etcd2.service
                    ConditionPathExists=!/etc/kubernetes/ssl/worker-$fqdn-key.pem
                    Description=Kubernetes Keys Generator

                    [Service]
                    Type=oneshot
                    ExecStart=/opt/kubernetes-init-ssl.sh
                - name: flanneld.service
                  drop-ins:
                    - name: 40-ExecStartPre-symlink.conf
                      content: |
                        [Service]
                        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env
                - name: format-data.service
                  command: start
                  content: |
                    [Unit]
                    Description=Formats the volume
                    After=dev-vdb.device
                    Requires=dev-vdb.device
                    [Service]
                    Type=oneshot
                    RemainAfterExit=yes
                    ExecStart=/opt/format-data.sh
                - name: data.mount
                  command: start
                  content: |
                    [Unit]
                    Description=Mount volume to /data
                    Requires=format-data.service
                    After=format-data.service
                    [Mount]
                    What=/dev/vdb
                    Where=/data
                    DirectoryMode=0777
                    Type=ext4
                - name: docker.service
                  drop-ins:
                    - name: 40-flannel.conf
                      content: |
                        [Unit]
                        Requires=data.mount flanneld.service
                        After=data.mount flanneld.service
                - name: syncthing.service
                  command: start
                  content: |
                    [Unit]
                    Description=Syncthing
                    After=docker.service
                    Requires=docker.service
                    [Service]
                    TimeoutStartSec=0
                    Restart=always
                    RestartSec=10
                    ExecStartPre=-/usr/bin/docker kill syncthing
                    ExecStartPre=-/usr/bin/docker rm syncthing
                    ExecStartPre=/usr/bin/docker pull cloudwattfr/syncthing
                    ExecStartPre=-/usr/bin/chmod -Rf 777 /data
                    ExecStart=/usr/bin/docker run --name syncthing --env 'GUI_USERNAME=$vpn_username' --env 'GUI_PASSWORD=$vpn_password' -v /data:/data --net=host cloudwattfr/syncthing
                    ExecStop=/usr/bin/docker stop syncthing
                - name: kubelet.service
                  command: start
                  content: |
                    [Unit]
                    Requires=docker.service generatessl.service
                    After=docker.service generatessl.service

                    [Service]
                    ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests

                    Environment=KUBELET_VERSION=v1.2.0_coreos.0
                    ExecStart=/opt/bin/kubelet-wrapper \
                      --api-servers=https://$master \
                      --register-node=true \
                      --allow-privileged=true \
                      --config=/etc/kubernetes/manifests \
                      --hostname-override=$private_ipv4 \
                      --cluster-dns=10.0.2.2 \
                      --cluster-domain=$domain \
                      --tls-cert-file=/etc/kubernetes/ssl/worker-$fqdn.pem \
                      --tls-private-key-file=/etc/kubernetes/ssl/worker-$fqdn-key.pem \
                      --kubeconfig=/etc/kubernetes/worker-$fqdn-kubeconfig.yaml
                    Restart=always
                    RestartSec=10
                    [Install]
                    WantedBy=multi-user.target
